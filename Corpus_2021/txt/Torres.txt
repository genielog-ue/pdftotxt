Nom du PDF : Torres.pdf
Titre du PDF : None
Auteur du PDF : 
Abstract : —We study a new content-based method for
the evaluation of text summarization systems without
human models which is used to produce system rankings.
The research is carried out using a new content-based
evaluation framework called F RESA to compute a variety of
divergences among probability distributions. We apply our
comparison framework to various well-established content-based
evaluation measures in text summarization such as C OVERAGE,
R ESPONSIVENESS, P YRAMIDS and ROUGE studying their
associations in various text summarization tasks including
generic multi-document summarization in English and French,
focus-based multi-document summarization in English and
generic single-document summarization in French and Spanish.
Index Terms—Text summarization evaluation, content-based
evaluation measures, divergences.

I. I NTRODUCTION

T

EXT summarization evaluation has always been a
complex and controversial issue in computational
linguistics. In the last decade, significant advances have been
made in this field as well as various evaluation measures have
been designed. Two evaluation campaigns have been led by
the U.S. agence DARPA. The first one, SUMMAC, ran from
